# Enhancing Higgs Boson Classification using Deep Learning  

This project implements a *Deep Learning model* to classify Higgs Boson particle events using high-dimensional data from the CERN dataset. The work focuses on improving classification accuracy using *feature engineering, hyperparameter tuning, and AutoML techniques*.  

## ğŸ“„ Publication

This project is based on my research published in:  
*International Journal of Scientific Research and Engineering Development (IJSRED)*  
Volume 8, Issue 2, 2025  
Title: Enhancing Higgs Boson Classification using Deep Learning

ğŸ“¥ **[Download the Published Paper](


## ğŸ“Œ Overview
The Higgs Boson dataset (introduced in the Kaggle Higgs Boson Challenge) involves distinguishing between signals representing Higgs Boson decay and background noise. This project applies *machine learning* and *deep learning* models to enhance classification performance.


## ğŸ“Š Key Features
- Implemented *8 machine learning algorithms* (Logistic Regression, KNN, SVM, Decision Tree, Random Forest, XGBoost, ANN, etc.).  
- Developed and optimized a *Deep Neural Network (DNN)* using TensorFlow/Keras.  
- Integrated *AutoML (H2O.ai)* achieving an *AUC of 1.0* on the dataset.  
- Applied *GPU acceleration* for faster training.

  ## ğŸ—‚ï¸ Dataset
- *Source*: [Kaggle - Higgs Boson Machine Learning Challenge](https://www.kaggle.com/c/higgs-boson)  
- The dataset contains multiple physics-derived features with binary labels for classification.


  ## ğŸ› ï¸ Technologies Used
- *Programming:* Python  
- *Libraries:* TensorFlow, Keras, Scikit-learn, H2O.ai AutoML, Pandas, NumPy, Matplotlib, Seaborn  
- *Environment:* Jupyter Notebook


  ## ğŸ§  Model Architecture
- Input Layer: Features from dataset  
- Hidden Layers: Dense layers with ReLU activation, Dropout for regularization  
- Output Layer: Sigmoid activation (binary classification)


  ## âœ… Results
| Model                  | Accuracy | AUC  |
|------------------------|----------|------|
| Logistic Regression    | 71%      | 0.75 |
| Random Forest          | 77%      | 0.80 |
| Artificial Neural Net  | 78%      | 0.81 |
| AutoML (H2O.ai)        | 95%+     | *1.0* |

The *AutoML model achieved the highest performance*, demonstrating the power of automated hyperparameter optimization and ensemble techniques.


## â–¶ï¸ How to View This Project
The *complete implementation code* is part of my academic major project and is not publicly shared.  

This repository includes:
- ğŸ“„ Project Overview (README)  
- ğŸ“‘ Research Publication (PDF)  
- ğŸ“ Methodology & Results Summary


  For collaboration or demonstration purposes, a simplified version can be shared upon request.  
ğŸ“§ *Contact*: jigeeshachowdary1@gmail.com  


## ğŸ‘¤ Author
*Paidipalli Jigeesha*  
- ğŸ“§ [jigeeshachowdary1@gmail.com](mailto:jigeeshachowdary1@gmail.com)  
- ğŸ”— [LinkedIn](https://linkedin.com/in/jigeesha-chowdary-98492a25b)  
- ğŸ’» [GitHub](https://github.com/Jigeeshapaidipalli)
